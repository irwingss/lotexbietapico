---
title: "Resultados y Conclusiones Lote X"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
```

# **Preliminares para iniciar con el proceso**

Se requieren 3 excels:

**A) [EXP]_coordenadas_puntos.xlsx**

Conteniendo la tabla inicial del REMA, donde se listan los puntos, sus coordenadas, altitud y profundidades. Columnas necesarias (respetar minúsculas):

- *punto:* código del punto (ej. L-X,6,PZEA9511-1)
- *norte:* latitud en UTM 17S (ej. 9530877.853)
- *este:* longitud en UTM 17S (ej. 484643.375)
- *altitud:* en metros sobre el nivel del mar (ej. 297)
- *prof:*  en metros (ej. 0.4)
- *ca:* el código de acción del punto (ej. 0006-5-2025-102). Esto no viene en la tabla inicial del rema pero se puede colocar uniformemente para todos los puntos de cada código de acción.


**B) [EXP]_marco_grillas_final.xlsx**

Contenido obtenido del marco de grillas generado antes de la selección de la muestra. Columnas necesarias (respetar minúsculas):

- *locacion:* locación (ej. EA7119)
- *celda_cod_plano:* código de la celda en plano obtenido del marco muestral (ej. B7)
- *celda:* código de la celda o COD_CELDA del marco muestral (ej. EA7119-B7)
- *grilla:* código de la grilla o COD_GRILLA del marco muestral (ej. EA7119-B7-1)
- *norte:* latitud del centroide de la grilla en UTM 17S (ej. 9531734.572)
- *este:*  longitud del centroide de la grilla en UTM 17S (ej. 485792.3644)
- *prof:*  en metros (ej. 0.3)
- *area:*  de la grilla en metros cuadrados (ej. 3.500001146)

**C) [EXP]_resultados_laboratorio.xlsx**

Contenido obtenido del marco de grillas generado antes de la selección de la muestra. Columnas necesarias (respetar minúsculas):

- *locacion:* locación (ej. EA7119)
- *punto:* código del punto (ej. L-X,6,PZEA9511-1)
- *tph:* valor de laboratorio del TPH del punto, sin decimales, sin comas ni letras. Reemplazar los valores no numéricos como <0.5 o <0.3 por 0 (ej. 10580)
- *prof:*  en metros (ej. 0.3)

# "Conclusión: Datos" debería ser una sola pestaña para carga y limpieza

En la app pues directamente se deben cargar los excels de trabajo, no será necesario definir expediente porque ya viene de fábrica. Podemos pedirle el código de expediente en el frontend para que al exportas las cosas le pongamos el prefijo respectivo. 

```{r}
# Definir expediente
exp = "0201-2025"

# Cargar data de REMA desde el frontend 
rar <- openxlsx::read.xlsx(paste0("excel_rar/",exp,"/",
                                  exp,"_resultados_laboratorio.xlsx"))



# Corregir locaciones vacías en la columna locacion del resultado de laboratorio
rar <- rar %>%
  dplyr::mutate(locacion = as.character(locacion)) %>%
  tidyr::fill(locacion, .direction = "down")

# No siempre es necesario, pero en caso se requiera extraer la locación directo del nombre del punto, se tomaría esto
# rar puede venir con los nombres faltanto PZ cuando es EA, deberían ser PZEA
# Sería bueno tener las limpiezas activables por separado

rar <- rar %>%
  mutate(
    loc2 = punto |>
      # elimina desde el último guion hasta el final (incluido el guion)
      str_remove("-[^-]+$") |>   
      # elimina "L-X,6,"
      str_replace("L-X,6,", "") |>       
      # elimina "PZ" solo si no forma parte de PZEA
      str_replace_all("(?<!PZ)PZ(?!EA)", ""),
    
    punto = punto |>
      # elimina "PZ" solo si no forma parte de PZEA
      str_replace_all("(?<!PZ)PZ(?!EA)", "") |>
      # restaura el prefijo "PZ" en los casos que inician con "EA" pero no con "PZEA"
      str_replace("^EA", "PZEA")
  )

# Cargar data de muestra desde el frontend
# En algunos casos se necesita chequear varias cosas
# La columna punto porque solo debe ELIMINAR el PZ cuando este PZ no es seguido de EA.
# Es decir, los PZ deben ser siempre PZEA, pero si el codigo contiene BAT, MNF u otra cosa, nunca deberían iniciar con PZ. Esta sección permite cargar y corregir eso, para mantener los BAT como BAT, los MNF y cualquier otro codigo como tal, y si tuvieran PZ eliminarlo. Mientras que los PZEA si es correcto que mantengan su PZ.
muestra <- openxlsx::read.xlsx(
  paste0("excel_rar/", exp, "/", exp, "_muestra_final.xlsx")) |> 
  mutate(
    punto = str_replace_all(punto, "(?<!PZ)PZ(?!EA)", ""),  # no elimina si es PZEA
    locacion = str_replace_all(locacion, "(?<!PZ)PZ(?!EA)", "")
  )

# Verificaciones de locaciones (match)
# mostrar
rar$loc2 |> unique() |> length()
muestra$locacion |> unique() |> length()

rar_loc <- rar$loc2 |> unique()
muestra_loc <- muestra$locacion |> unique()
setdiff(muestra_loc,rar_loc)
setdiff(rar_loc,muestra_loc)

# Verificaciones de puntos (no match)
# mostrar
rar$punto |> unique() |> length() # 549
muestra$punto |> unique() |> length() # 562

rar_punto <- rar$punto |> unique()
muestra_punto <- muestra$punto |> unique()
setdiff(muestra_punto,rar_punto) # 13 puntos descartados (OK)
setdiff(rar_punto,muestra_punto)

# Unificar la información de REMA con la muestra 
# Debemos ser capaces de en el frontend poder seleccionar qué columnas (de ambas tablas madre) tendrá nuestra tabla final. Siempre la RAR es nuestra tabla a la que vamos a enriquecer.
juntos_rar_muestra <- left_join(rar, muestra %>% 
                    dplyr::select(norte, este, 
                                  grilla, celda, 
                                  superposiciones, 
                                  cod_colectora, punto), 
                  by = "punto")

# Exportación de la muestra enriquecida
openxlsx::write.xlsx(juntos_rar_muestra, 
                     paste0("excel_rar/",exp,"/",
                                  exp,"_muestra_enriquecida.xlsx"))

# Cambiar nombre para usar 
muestra_final_e <- juntos_rar_muestra
```


# CONCLUSION NIVEL GRILLA

```{r}
# Tabla mostrar en el frontend, y que sea descargable en excel
muestra_final_e %>% 
  filter(tph > 10000)

# Códigos de grilla para filtrar shapefile luego
superan_grilla <- muestra_final_e %>% 
  filter(tph > 10000) %>% 
  pull(grilla)
superan_grilla

# ---

# Aquí deberíamos poder subir el shapefile de grillas para filtrarlo y exportar un shapefile de grillas filtrado (grillas impactadas)

# ----

# Mostrar códigos de campo/colectora de los puntos de 
superan_cod_punto <- muestra_final_e %>% 
  filter(tph > 10000) %>% 
  pull(punto)
superan_cod_punto
```

# "Conclusión: Resultados" debería ser una sola pestaña

## CONCLUSION NIVEL CELDAS

```{r}
# Revisar la cantidad de puntos por locación
conteo_loc <- muestra_final_e %>% count(locacion) %>% arrange(n) 

if(any(conteo_loc$n < 3)){
  print("Hay locaciones con menos de 3 puntos")
    # aquí deberíamos mostrar cuales locaciones tienen menos de 3 puntos
} else {
  print("El recuento de puntos de muestreo por locaciones va bien, todas >3 puntos")
        }

# Revisar la cantidad de puntos por celda
conteo_cel <- muestra_final_e %>% count(celda) %>% arrange(n) 

if(any(conteo_loc$n < 3)){
  print("Hay locaciones con menos de 3 puntos")
  # aquí deberíamos mostrar cuales celdas tienen menos de 3 puntos
} else {
  print("El recuento de puntos de muestreo por celdas va bien, todas >3 puntos")
}


if(any(conteo_cel$celda == "" | conteo_cel$celda == " ")){
  print("Hay puntos que no tienen celda")
  # aquí deberíamos mostrar cuales no tienen celda
} else {
  print("Todos los puntos tienen un código de celda asignado")
}

# Mostrar las celdas
print(conteo_loc)

# Creando el objeto survey con el diseño de estudios complejo
library(survey)
survey_design_obj <- svydesign(
  ids = ~ punto,    
  strata = ~ locacion+celda,    
  probs =  ~1,    
  data = muestra_final_e,
  nest = TRUE
)

# Calculando los promedios
Promedio_celdas <- svyby(~tph, ~celda, 
      survey_design_obj, 
      svymean, 
      na.rm = TRUE, 
      keep.var = TRUE)

# Añadiendo información de la incertidumbre de la estimación de los promedios
# valor crítico
z <- qnorm(0.975)

Promedio_celdas <- Promedio_celdas %>%
  mutate(
    IC95_low  = tph - z * se,
    IC95_high = tph + z * se,
    RSE        = (se / tph) * 100,
    impactada = ifelse(tph > 10000, 1, 0)
  ) %>% 
  mutate(IC95_low = ifelse(IC95_low < 1, 0, IC95_low) |> round(2),
         IC95_high = ifelse(IC95_high < 1, 0, IC95_high) |> round(2),
         range = IC95_high - IC95_low)

# -----------------------------------------------------------------------------
### Añadiendo la proporción de puntos que superan el umbral por celda

# Para hallar la proporción de puntos > 10000 dentro de las celdas
library(dplyr)
library(survey)

# Umbral de impacto
threshold <- 10000

# Valor crítico para IC 95%
z <- qnorm(0.975)

# 1) Calcular proporción de puntos > umbral por celda
Promedio_prop <- svyby(
  ~I(tph > threshold),
  ~celda,
  survey_design_obj,
  svymean,
  na.rm = TRUE,
  keep.var = TRUE
) %>% 
  rename(
    prop_exceed  = `I(tph > threshold)TRUE`,
    se_prop      = `se.I(tph > threshold)TRUE`
  ) %>%
  mutate(
    IC95_low_prop  = pmax(prop_exceed - z * se_prop, 0),
    IC95_high_prop = pmin(prop_exceed + z * se_prop, 1)
  ) %>% 
  select(celda,  prop_exceed, se_prop, IC95_low_prop, IC95_high_prop)

# 2) Unir con la tabla de promedios e IC de TPH
Promedio_celdas_final <- Promedio_celdas %>%
  left_join(
    Promedio_prop %>%
      select(celda, prop_exceed, IC95_low_prop, IC95_high_prop),
    by = "celda"
  )

# 3) Añadir conteo de puntos totales y impactados por celda
conteo_puntos_celda <- muestra_final_e %>%
  group_by(celda) %>%
  summarise(
    n_puntos_total = n(),
    n_puntos_impactados = sum(tph > 10000, na.rm = TRUE),
    .groups = "drop"
  )

# 4) Unir con la tabla de promedios final
Promedio_celdas_final <- Promedio_celdas_final %>%
  left_join(conteo_puntos_celda, by = "celda")

# 5) Añadir criterio de impacto por celda
Promedio_celdas_final <- Promedio_celdas_final %>%
  mutate(
    impactada_por_tph = ifelse(tph > 10000, "Sí", "No"),
    impactada_por_proporcion = ifelse(prop_exceed > 0.5, "Sí", "No"),
    criterio_de_impacto = case_when(
      impactada_por_tph == "Sí" & impactada_por_proporcion == "Sí" ~ "Ambos criterios",
      impactada_por_tph == "Sí" ~ "Solo TPH promedio",
      impactada_por_proporcion == "Sí" ~ "Solo proporción",
      TRUE ~ "No impactada"
    )
  )

# Mostrar tabla final de celdas impactadas
Promedio_celdas_final %>%
  filter(impactada_por_tph == "Sí" | impactada_por_proporcion == "Sí") %>%
  select(celda, tph, IC95_low, IC95_high, prop_exceed, n_puntos_total, 
         n_puntos_impactados, criterio_de_impacto)

# ---

# FILTRADO DE SHAPEFILE DE CELDAS:
# Aquí deberías cargar el shapefile de celdas desde el frontend de la app.
# Filtrar por las celdas impactadas según los criterios definidos:
# - Criterio 1: TPH promedio > 10000
# - Criterio 2: Proporción de puntos impactados > 50%
# Añadir la columna 'criterio_de_impacto' al shapefile exportado.

# Ejemplo de código para filtrar shapefile (ejecutar en la app):
# library(sf)
# shp_celdas <- st_read("ruta/al/shapefile_celdas.shp")
# celdas_impactadas <- Promedio_celdas_final %>%
#   filter(impactada_por_tph == "Sí" | impactada_por_proporcion == "Sí") %>%
#   pull(celda)
# shp_celdas_filtrado <- shp_celdas %>%
#   filter(COD_CELDA %in% celdas_impactadas) %>%
#   left_join(
#     Promedio_celdas_final %>% select(celda, criterio_de_impacto),
#     by = c("COD_CELDA" = "celda")
#   )
# st_write(shp_celdas_filtrado, "celdas_impactadas.shp")

# ----

#-------------------------------------------------------------------------
# Códigos de celda para filtrar shapefile luego
superan_celdas_tph_prom <- Promedio_celdas_final %>% 
  filter(tph > 10000) %>% 
  pull(celda)
superan_celdas_tph_prom

superan_celdas_proporcion <- Promedio_celdas_final %>% 
  filter(prop_exceed > 0.5) %>% 
  pull(celda)
superan_celdas_proporcion 

# mostrar la tabla Promedio_celdas_final filtrada para indicar las celdas impactadas y su valor de tph > 10000 o de sobrepasar proporción de puntos que exceden los 10000 sobre el 50%

```

## CONCLUSIÓN NIVEL LOCACIÓN

```{r}
# Creando el objeto survey con el diseño de estudios complejo
library(survey)
survey_design_obj2 <- svydesign(
  ids = ~punto,    
  strata = ~locacion,    
  probs =  ~1,    
  data = muestra_final_e,
  nest = TRUE
)

# summary(survey_design_obj)

# Calculando los promedios
Promedio_locaciones <- svyby(~tph, ~ locacion, 
      survey_design_obj2, 
      svymean, 
      na.rm = TRUE, 
      keep.var = TRUE)

rownames(Promedio_locaciones) <- NULL

# Añadiendo información de la incertidumbre de la estimación de los promedios
# valor crítico
z <- qnorm(0.975)

Promedio_locaciones <- Promedio_locaciones %>%
  mutate(
    IC95_low  = tph - z * se,
    IC95_high = tph + z * se,
    RSE        = (se / tph) * 100,
    impactada = ifelse(tph > 10000, 1, 0)
  ) %>% 
  mutate(IC95_low = ifelse(IC95_low < 1, 0, IC95_low) |> round(2),
         IC95_high = ifelse(IC95_high < 1, 0, IC95_high) |> round(2),
         range = IC95_high - IC95_low)

Promedio_locaciones

# -----------------------------------------------------------------------------
### Añadiendo la proporción de puntos que superan el umbral por locación

# Umbral de impacto
threshold <- 10000

# Valor crítico para IC 95%
z <- qnorm(0.975)

# 1) Calcular proporción de puntos > umbral por locación
Promedio_prop_loc <- svyby(
  ~I(tph > threshold),
  ~locacion,
  survey_design_obj2,
  svymean,
  na.rm = TRUE,
  keep.var = TRUE
) %>% 
  rename(
    prop_exceed  = `I(tph > threshold)TRUE`,
    se_prop      = `se.I(tph > threshold)TRUE`
  ) %>%
  mutate(
    IC95_low_prop  = pmax(prop_exceed - z * se_prop, 0),
    IC95_high_prop = pmin(prop_exceed + z * se_prop, 1)
  ) %>% 
  select(locacion, prop_exceed, se_prop, IC95_low_prop, IC95_high_prop)

# 2) Añadir conteo de puntos totales y impactados por locación
conteo_puntos_loc <- muestra_final_e %>%
  group_by(locacion) %>%
  summarise(
    n_puntos_total = n(),
    n_puntos_impactados = sum(tph > 10000, na.rm = TRUE),
    .groups = "drop"
  )

# 3) Unir con la tabla de promedios
Promedio_locaciones_final <- Promedio_locaciones %>%
  left_join(
    Promedio_prop_loc %>%
      select(locacion, prop_exceed, IC95_low_prop, IC95_high_prop),
    by = "locacion"
  ) %>%
  left_join(conteo_puntos_loc, by = "locacion")

# 4) Añadir criterio de impacto por locación
Promedio_locaciones_final <- Promedio_locaciones_final %>%
  mutate(
    impactada_por_tph = ifelse(tph > 10000, "Sí", "No"),
    impactada_por_proporcion = ifelse(prop_exceed > 0.5, "Sí", "No"),
    criterio_de_impacto = case_when(
      impactada_por_tph == "Sí" & impactada_por_proporcion == "Sí" ~ "Ambos criterios",
      impactada_por_tph == "Sí" ~ "Solo TPH promedio",
      impactada_por_proporcion == "Sí" ~ "Solo proporción",
      TRUE ~ "No impactada"
    )
  )

# Mostrar tabla final de locaciones
Promedio_locaciones_final

#-------------------------------------------------------------------------
# Códigos de locación para filtrar shapefile luego
superan_loc_tph_prom <- Promedio_locaciones_final %>% 
  filter(tph > 10000) %>% 
  pull(locacion)
superan_loc_tph_prom

# Filtrar las locaciones que tienen prop_exceed > 0.5
superan_loc_proporcion <- Promedio_locaciones_final %>% 
  filter(prop_exceed > 0.5) %>% 
  pull(locacion)
superan_loc_proporcion

# Mostrar la tabla Promedio_locaciones filtrada para indicar las locaciones impactadas
Promedio_locaciones_final %>%
  filter(impactada_por_tph == "Sí" | impactada_por_proporcion == "Sí") %>%
  select(locacion, tph, IC95_low, IC95_high, prop_exceed, n_puntos_total, 
         n_puntos_impactados, criterio_de_impacto)

```

## REPORTE FINAL RESUMEN

```{r}
# Superan
superan_grilla # codigo que encaja con la columna COD_GRILLA del shapefile shp_marco_grillas
superan_cod_punto
superan_celdas_tph_prom # codigo que encaja co la columa COD_UNIC celda del shapefile shp_marco_celdas
superan_celdas_proporcion # codigo que encaja co la columa COD_UNIC celda del shapefile shp_marco_celdas
superan_celdas_proporcion

# Tablas
muestra_final_e %>% 
  filter(tph > 10000)

Promedio_celdas_final 
Promedio_locaciones
```

# "Conclusión: Vértices" debería ser una sola pestaña

## OBTENER VERTICES DE GRILLAS

```{r}
# Instala si no lo tienes
# install.packages("sf")

# Cargar librería
library(sf)

# Cargar shapefiles
shp_marco_grillas <- st_read("C:/Users/isald/Documents/CLONES/oefa-2025/01-ProyectoR-por-expediente/RProj_Procesamiento_Resultados_Lab/excel_rar/0121-2025/shp/shp marcos/marco_grillas.shp")

shp_marco_celdas <- st_read("C:/Users/isald/Documents/CLONES/oefa-2025/01-ProyectoR-por-expediente/RProj_Procesamiento_Resultados_Lab/excel_rar/0121-2025/shp/shp marcos/marco_celdas.shp")


```

```{r}
# =========================
# Paquetes
# =========================
library(sf)
library(dplyr)
library(openxlsx)

# =========================
# Funciones utilitarias
# =========================
to_key <- function(x) trimws(as.character(x))  # normaliza llaves

#---- Función genérica: extrae vértices de polígonos que coinciden con "codes"
# - sf_obj: objeto sf con geometrías POLYGON/MULTIPOLYGON
# - code_col: nombre de la columna con el código (string)
# - codes: vector de códigos a filtrar
get_vertices <- function(sf_obj, code_col, codes) {
  # Filtrar los features por código
  sf_filtrado <- sf_obj %>%
    filter(.data[[code_col]] %in% codes)

  # Si no hay coincidencias, devolver tibble vacío "ordenado"
  if (nrow(sf_filtrado) == 0) {
    return(tibble::tibble(
      !!code_col := character(),
      part_id = integer(),
      ring_id = integer(),
      vertex_id = integer(),
      X = double(),
      Y = double()
    ))
  }

  # Casting progresivo para preservar estructura (MultiPol -> Pol -> MultiLine -> Line -> Point)
  # y crear IDs de parte (part_id), anillo (ring_id) y secuencia de vértice (vertex_id).
  sf_pts <- sf_filtrado %>%
    st_cast("MULTIPOLYGON") %>%
    st_cast("POLYGON") %>%
    group_by(.data[[code_col]]) %>%
    mutate(part_id = dplyr::row_number()) %>%        # cada parte (polígono) dentro del feature
    ungroup() %>%
    st_cast("MULTILINESTRING") %>%
    st_cast("LINESTRING") %>%
    group_by(.data[[code_col]], part_id) %>%
    mutate(ring_id = dplyr::row_number()) %>%        # 1 = anillo exterior, >1 = agujeros (típicamente)
    ungroup() %>%
    st_cast("POINT") %>%
    group_by(.data[[code_col]], part_id, ring_id) %>%
    mutate(vertex_id = dplyr::row_number()) %>%
    ungroup()

  # Extraer coordenadas y devolver como data.frame plano
  coords <- sf::st_coordinates(sf_pts)
  out <- dplyr::bind_cols(
    sf_pts |> st_drop_geometry() |> select(all_of(code_col), part_id, ring_id, vertex_id),
    as.data.frame(coords)[, c("X", "Y")]
  )

  # Orden útil
  out %>% arrange(.data[[code_col]], part_id, ring_id, vertex_id)
}

# =========================
# VÉRTICES: GRILLAS filtradas por superan_grilla
# =========================
stopifnot(exists("shp_marco_grillas"))
stopifnot(exists("muestra_final_e"))
stopifnot(exists("superan_grilla"))

# 1) Obtener los vértices SOLO de las grillas en 'superan_grilla'
vertices_grillas <- get_vertices(
  sf_obj  = shp_marco_grillas,
  code_col = "COD_GRILLA",
  codes    = superan_grilla
)

# 2) Detectar la columna del CÓDIGO DE PUNTO en 'muestra_final_e'
cand_cols <- c("COD_PUNTO","cod_punto","COD_MUESTRA","codigo_punto",
               "CODIGO","codigo","PUNTO","punto")
punto_col <- intersect(cand_cols, names(muestra_final_e))[1]
if (is.na(punto_col)) stop("No encuentro la columna del código de punto en 'muestra_final_e'. Ajusta 'punto_col'.")

# 3) Lookup (punto, tph, grilla) SOLO para las grillas de superan_grilla
stopifnot(all(c("grilla","tph") %in% names(muestra_final_e)))
lk_punto_grilla <- muestra_final_e %>%
  filter(grilla %in% superan_grilla) %>%
  transmute(
    codigo_punto = .data[[punto_col]],
    COD_GRILLA   = to_key(grilla),
    tph
  ) %>%
  distinct()

# 4) Atributos de grilla (LOCACION, COD_GRILLA, AREA) desde el shapefile
attrs_grillas <- shp_marco_grillas %>%
  st_drop_geometry() %>%
  transmute(
    COD_GRILLA = to_key(COD_GRILLA),
    LOCACION,
    AREA
  )

# 5) Unir TODO con los vértices
#    - inner_join con lk_punto_grilla: mantiene vértices solo donde hay puntos asociados
#    - si quieres mantener vértices aun sin puntos, usa left_join() en su lugar
vertices_grillas_enriq <- vertices_grillas %>%
  mutate(COD_GRILLA = to_key(COD_GRILLA)) %>%
  left_join(attrs_grillas,   by = "COD_GRILLA") %>%
  inner_join(lk_punto_grilla, by = "COD_GRILLA") %>%
  relocate(codigo_punto, tph, LOCACION, COD_GRILLA, AREA, .before = part_id) %>%
  rename(ESTE = X, NORTE = Y)

# 6) Exportar a Excel
out_dir <- "excel_rar/0121-2025/vertices"
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

write.xlsx(
  vertices_grillas_enriq,
  file.path(out_dir, "vert_grillas_enriquecido.xlsx")
)

# =========================
# Resultado:
# columnas clave -> codigo_punto, tph, LOCACION, COD_GRILLA, AREA, part_id, ring_id, vertex_id, ESTE, NORTE
# =========================


```

## OBTENER VERTICES DE CELDAS

```{r}
# =========================
# Paquetes
# =========================
library(sf)
library(dplyr)
library(openxlsx)

# =========================
# Parámetros
# =========================
UMBRAL_TPH <- 10000  # cambia aquí si el umbral varía

# =========================
# Helpers
# =========================
to_key <- function(x) trimws(as.character(x))

find_col <- function(df, candidates, label = "columna requerida") {
  col <- intersect(candidates, names(df))[1]
  if (is.na(col)) stop(sprintf("No encuentro %s. Busqué: %s", label, paste(candidates, collapse = ", ")))
  col
}

#---- Función genérica: extrae vértices de polígonos que coinciden con "codes"
get_vertices <- function(sf_obj, code_col, codes) {
  sf_filtrado <- sf_obj %>% filter(.data[[code_col]] %in% codes)
  if (nrow(sf_filtrado) == 0) {
    return(tibble::tibble(
      !!code_col := character(),
      part_id = integer(), ring_id = integer(), vertex_id = integer(),
      X = double(), Y = double()
    ))
  }
  sf_pts <- sf_filtrado %>%
    st_cast("MULTIPOLYGON") %>%
    st_cast("POLYGON") %>%
    group_by(.data[[code_col]]) %>%
    mutate(part_id = dplyr::row_number()) %>%
    ungroup() %>%
    st_cast("MULTILINESTRING") %>%
    st_cast("LINESTRING") %>%
    group_by(.data[[code_col]], part_id) %>%
    mutate(ring_id = dplyr::row_number()) %>%
    ungroup() %>%
    st_cast("POINT") %>%
    group_by(.data[[code_col]], part_id, ring_id) %>%
    mutate(vertex_id = dplyr::row_number()) %>%
    ungroup()
  coords <- sf::st_coordinates(sf_pts)
  dplyr::bind_cols(
    sf_pts |> st_drop_geometry() |> select(all_of(code_col), part_id, ring_id, vertex_id),
    as.data.frame(coords)[, c("X", "Y")]
  ) %>% arrange(.data[[code_col]], part_id, ring_id, vertex_id)
}

# =========================
# Requisitos de objetos
# =========================
stopifnot(exists("shp_marco_celdas"))
stopifnot(exists("Promedio_celdas_final"))
stopifnot(exists("muestra_final_e"))
stopifnot(exists("superan_celdas_tph_prom"))
stopifnot(exists("superan_celdas_proporcion"))

# Detectar columnas clave
shp_code_col_celdas <- find_col(shp_marco_celdas,
  c("COD_UNIC","COD_CELDA","celda","CELDA","CODIGO","COD_UNICO"),
  "la columna código de celda en shapefile de celdas"
)
mf_celda_col  <- find_col(muestra_final_e, c("celda","COD_UNIC","COD_CELDA","CELDA"), "la columna 'celda' en muestra_final_e")
mf_punto_col  <- find_col(muestra_final_e, c("punto","PUNTO","COD_PUNTO","cod_punto","COD_MUESTRA","codigo_punto"),
                          "la columna 'punto' (código de punto) en muestra_final_e")
mf_tph        <- find_col(muestra_final_e, c("TPH","tph"), "la columna 'TPH/tph' en muestra_final_e")

# Atributos desde shapefile de celdas
attrs_celdas <- shp_marco_celdas %>%
  st_drop_geometry() %>%
  transmute(
    COD_UNIC = to_key(.data[[shp_code_col_celdas]]),
    LOCACION, AREA
  )

# Promedio TPH por celda
prom_celdas <- Promedio_celdas_final %>%
  transmute(
    COD_UNIC   = to_key(celda),
    tph_celda  = tph
  ) %>%
  distinct()

# Tabla base de puntos (NO se filtra aquí; se usa para totales y superan)
mf_puntos <- muestra_final_e %>%
  transmute(
    COD_UNIC = to_key(.data[[mf_celda_col]]),
    punto    = as.character(.data[[mf_punto_col]]),
    tph      = as.numeric(.data[[mf_tph]])
  )

# Carpeta salida
out_dir <- "excel_rar/0121-2025/vertices"
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)

# =========================
# Función generadora para CELDAS
# =========================
build_vertices_celdas <- function(celdas_vec, outfile) {
  codes <- unique(to_key(as.character(celdas_vec)))

  # Vértices desde shapefile (según las celdas pedidas)
  vtx <- get_vertices(
    sf_obj   = shp_marco_celdas,
    code_col = shp_code_col_celdas,
    codes    = codes
  )

  # Normalizar nombre del código a COD_UNIC
  if (shp_code_col_celdas != "COD_UNIC") {
    vtx <- vtx %>% rename(COD_UNIC = all_of(shp_code_col_celdas))
  }

  # ---- Totales de puntos por celda (denominador)
  totales_por_celda <- mf_puntos %>%
    filter(COD_UNIC %in% codes) %>%
    group_by(COD_UNIC) %>%
    summarise(n_puntos_total = n_distinct(punto), .groups = "drop")

  # ---- Puntos que superan (lista + conteo por celda)
  puntos_superan_df <- mf_puntos %>%
    filter(COD_UNIC %in% codes, !is.na(tph), tph > UMBRAL_TPH) %>%
    group_by(COD_UNIC) %>%
    summarise(
      puntos_superan     = paste(sort(unique(punto)), collapse = "; "),
      n_puntos_superan   = dplyr::n_distinct(punto),
      .groups = "drop"
    )

  # ---- Proporción en %
  prop_superan <- totales_por_celda %>%
    left_join(puntos_superan_df, by = "COD_UNIC") %>%
    mutate(
      n_puntos_superan = coalesce(n_puntos_superan, 0L),
      prop_superan_pct = if_else(n_puntos_total > 0,
                                 round(100 * n_puntos_superan / n_puntos_total, 2),
                                 NA_real_)
    ) %>%
    select(COD_UNIC, puntos_superan, prop_superan_pct)

  # Unir atributos + promedio + proporción/lista de puntos
  out <- vtx %>%
    mutate(COD_UNIC = to_key(COD_UNIC)) %>%
    left_join(attrs_celdas, by = "COD_UNIC") %>%
    left_join(prom_celdas,   by = "COD_UNIC") %>%
    left_join(prop_superan,  by = "COD_UNIC") %>%
    relocate(COD_UNIC, LOCACION, AREA, tph_celda, puntos_superan, prop_superan_pct, .before = part_id) %>%
    rename(ESTE = X, NORTE = Y)

  write.xlsx(out, file.path(out_dir, outfile))
  out
}

# =========================
# Salidas requeridas
# =========================

# 1) Celdas impactadas por PROMEDIO TPH
vertices_celdas_tph_prom_enriq <- build_vertices_celdas(
  superan_celdas_tph_prom,
  "vert_celdas_prom_enriquecido.xlsx"
)

# 2) Celdas impactadas por PROPORCIÓN (>50% puntos impactados)
vertices_celdas_prop_enriq <- build_vertices_celdas(
  superan_celdas_proporcion,
  "vert_celdas_prop_enriquecido.xlsx"
)

# Resultado: dos archivos en 'excel_rar/0121-2025/vertices/'
# - vert_celdas_prom_enriquecido.xlsx
# - vert_celdas_prop_enriquecido.xlsx
# Columnas clave: COD_UNIC, LOCACION, AREA, tph_celda, puntos_superan, prop_superan_pct, part_id, ring_id, vertex_id, ESTE, NORTE


```

## No se exportan vértices de locaciones porque es demasiado, solo grillas y celdas como ya las tenemos en este punto
